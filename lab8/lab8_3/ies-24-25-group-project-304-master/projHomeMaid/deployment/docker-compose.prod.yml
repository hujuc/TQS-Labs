services:

  mongo:
    image: mongo:latest
    container_name: mongo
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')", "--host", "localhost", "--port", "27017"]
      interval: 10s
      retries: 3
      start_period: 10s
      timeout: 5s

  backend:
    build:
      context: ../backend
    depends_on:
      mongo:
        condition: service_healthy
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      SPRING_APPLICATION_JSON: '{
      "spring.data.mongodb.uri":"mongodb://mongo:27017/smart_home_mongodb",
      "spring.data.mongodb.database":"smart_home_mongodb",
      "server.port":"8080",
      "logging.level.root":"WARN",
      "logging.level.org.springframework":"INFO",
      "spring.main.web-application-type":"servlet"
      }'
      INFLUXDB_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXDB_URL: "http://influxdb:8086"  # Endereço do InfluxDB
      INFLUXDB_BUCKET: "sensor_data"       # Bucket configurado
      INFLUXDB_ORG: "HomeMaidOrg"          # Organização configurada

  frontend:
    build:
      context: ../frontend
    depends_on:
      - backend
    ports:
      - 80:80
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    environment:
      VITE_API_URL: http://backend:8080

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.4
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181

  kafka:
    image: confluentinc/cp-kafka:7.4.4
    depends_on:
      - zookeeper
    ports:
      - 29092:29092
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_MS: 10000
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 5000
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      # Aumentar o tamanho das mensagens
      KAFKA_MESSAGE_MAX_BYTES: 1048576000    # 1 GB
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 1048576000
    healthcheck:
      test: [ "CMD", "kafka-broker-api-versions", "--bootstrap-server", "kafka:9092" ]
      interval: 30s
      retries: 5

  kafdrop:
    image: obsidiandynamics/kafdrop:4.0.2
    ports:
      - "9009:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"
      SERVER_SERVLET_CONTEXTPATH: "/"

  data_generator:
    build:
      context: ../data_generator
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - KAFKA_BROKER=kafka:9092

  influxdb:
    image: influxdb:2.7
    container_name: influxdb_dev
    ports:
      - "8086:8086"
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=admin123
      - DOCKER_INFLUXDB_INIT_ORG=HomeMaidOrg
      - DOCKER_INFLUXDB_INIT_BUCKET=sensor_data
    volumes:
      - influxdb_dev_data:/var/lib/influxdb2


volumes:
  mongodb_data:
  influxdb_dev_data: